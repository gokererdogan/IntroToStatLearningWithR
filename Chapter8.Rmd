---
output: html_document
---
# Introduction to Statistical Learning - Chapter 8

## Question 3
```{r}
p1 = seq(from = 0, to = 1, length.out = 51)
class.err = 1 - apply(cbind(p1, 1-p1), 1, max)
gini = p1*(1-p1)
cross = -(p1*log(p1) + (1-p1)*log(1-p1))
#par(mfrow=c(1,3))
plot(p1, class.err, type='l', col='blue', ylim=c(0,0.7))
lines(p1, gini, type='l', col='red')
lines(p1, cross, type='l', col='green')
legend('topright', legend=c('misclass', 'gini', 'cross ent'), col = c('blue','red','green'), lwd=1)
```

## Question 5
```{r}
probs = c(0.1, 0.15, 0.2, 0.2, 0.55, 0.6, 0.6, 0.65, 0.7, 0.75)
votes = probs>0.5
sum(votes)
avg.prob = mean(probs)
avg.prob
```

## Question 7
```{r}
library(MASS)
library(randomForest)
set.seed(1)
train = sample(1:nrow(Boston), nrow(Boston)/2)
test = -train
# vary mtry
mtry = 1:13
rf.err = rep(NA, 13)
for( i in mtry ){
  rf.fit = randomForest(formula = medv~., data = Boston[train,], mtry=i, ntree = 500)
  rf.pred = predict(object = rf.fit, newdata = Boston[test,])
  rf.err[i] = mean((rf.pred-Boston[test, 'medv'])^2)
}
which.min(rf.err)
plot(mtry, rf.err, type='b', lwd=2, col='red')
# vary ntree
ntree = seq(from = 25, to = 600, by = 50)
rf.ntree.err = rep(NA, length(ntree))
for( i in 1:length(ntree) ){
  rf.fit = randomForest(formula = medv~., data = Boston[train,], mtry=6, ntree = ntree[i])
  rf.pred = predict(object = rf.fit, newdata = Boston[test,])
  rf.ntree.err[i] = mean((rf.pred-Boston[test, 'medv'])^2)
}
plot(ntree, rf.ntree.err, type='b', lwd=2, col='red')
```

## Question 8
```{r}
library(ISLR)
library(tree)
set.seed(1)
train = sample(1:400, 200)
test = -train

tree.fit = tree(formula = Sales~., data = Carseats[train,])
tree.pred = predict(object = tree.fit, newdata = Carseats[test,])
mean((tree.pred - Carseats[test, 'Sales'])^2)
summary(tree.fit)
plot(tree.fit)
text(tree.fit, pretty=0)

cv.tree.fit = cv.tree(object = tree.fit)
plot(cv.tree.fit$size, cv.tree.fit$dev, type='b')
which.min(cv.tree.fit$dev)
prune.tree.fit = prune.tree(tree = tree.fit, best = 12)
prune.tree.pred = predict(object = prune.tree.fit, newdata = Carseats[test,])
mean((prune.tree.pred - Carseats[test, 'Sales'])^2)
```

```{r}
library(randomForest)
bag.fit = randomForest(formula = Sales~., data = Carseats[train,], ntree = 1000, mtry = 10, importance = T)
bag.pred = predict(object = bag.fit, newdata = Carseats[test,])
mean((bag.pred - Carseats[test, 'Sales'])^2)
importance(bag.fit)
```

```{r}
mtry = 1:9
rf.fits = list()
rf.err = rep(NA, 9)
for( i in mtry )
{
  rf.fit = randomForest(formula = Sales~., data = Carseats[train,], ntree = 1000, mtry = i, importance = T)
  rf.fits[[i]] = rf.fit
  rf.pred = predict(object = rf.fit, newdata = Carseats[test,])
  rf.err[i] = mean((rf.pred - Carseats[test, 'Sales'])^2)
}
plot(mtry, rf.err, type='b', lwd=2, col='red')
which.min(rf.err)
min(rf.err)
```

## Question 9
```{r}
library(ISLR)
set.seed(1)
train = sample(1:nrow(OJ), 800)
test = -train

library(tree)
tree.fit = tree(formula = Purchase~., data = OJ[train,])
tree.train.pred = predict(object = tree.fit, newdata = OJ[train,], type='class')
tree.pred = predict(object = tree.fit, newdata = OJ[test,], type='class')
1-mean((tree.train.pred==OJ[train, 'Purchase']))
1-mean((tree.pred==OJ[test, 'Purchase']))
summary(tree.fit)
plot(tree.fit)
text(tree.fit, pretty=0)

table(tree.pred, OJ[test, 'Purchase'])

cv.tree.fit = cv.tree(object = tree.fit, FUN = prune.misclass)
plot(cv.tree.fit$size, cv.tree.fit$dev, type='b')
which.min(cv.tree.fit$dev)
cv.tree.fit$size[which.min(cv.tree.fit$dev)]
prune.tree.fit = prune.tree(tree = tree.fit, best = 2)
prune.tree.train.pred = predict(object = prune.tree.fit, newdata = OJ[train,], type='class')
prune.tree.pred = predict(object = prune.tree.fit, newdata = OJ[test,], type='class')
1-mean((prune.tree.train.pred==OJ[train, 'Purchase']))
1-mean((prune.tree.pred==OJ[test, 'Purchase']))
```






